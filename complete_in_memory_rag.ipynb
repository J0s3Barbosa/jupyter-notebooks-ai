{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html#langchain_ollama.chat_models.ChatOllama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes an OllamaEmbeddings instance with the specified model.\n",
    "\n",
    "The OllamaEmbeddings class is used to generate embeddings for text using the LLaMA language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.2:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes an in-memory vector store using the provided embeddings.\n",
    "The `InMemoryVectorStore` is a simple vector store implementation that stores the embeddings in memory. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "document_1 = Document(id=\"1\", page_content=\"Jose is an AI engineer\", metadata={\"Jose\": \"AI engineer\"})\n",
    "document_2 = Document(id=\"2\", page_content=\"LangGraph is a library for building stateful, multi-actor applications with LLMs\", metadata={\"LangGraph\": \"LLMs\"})\n",
    "document_3 = Document(id=\"3\", page_content=\"Python is a versatile programming language\", metadata={\"Python\": \"programming language\"})\n",
    "document_4 = Document(id=\"4\", page_content=\"Machine learning is a subset of artificial intelligence\", metadata={\"Machine learning\": \"AI\"})\n",
    "document_5 = Document(id=\"5\", page_content=\"Natural language processing deals with interactions between computers and human language\", metadata={\"NLP\": \"human language\"})\n",
    "document_6 = Document(id=\"6\", page_content=\"LlamaIndex is a data framework for LLM-based applications\", metadata={\"LlamaIndex\": \"data framework\"})\n",
    "document_7 = Document(id=\"7\", page_content=\"Caching is a scalability pattern that stores and reuses the results of expensive operations\", metadata={\"Scalability\": \"caching\"})\n",
    "document_8 = Document(id=\"8\", page_content=\"Parallelism is a scalability pattern that executes multiple tasks simultaneously\", metadata={\"Scalability\": \"parallelism\"})\n",
    "document_9 = Document(id=\"9\", page_content=\"Routing is a scalability pattern that directs requests to appropriate resources\", metadata={\"Scalability\": \"routing\"})\n",
    "document_10 = Document(id=\"10\", page_content=\"Asynchrony is a scalability pattern that allows non-blocking operations\", metadata={\"Scalability\": \"asynchrony\"})\n",
    "document_11 = Document(id=\"11\", page_content=\"Decoupling is a scalability pattern that separates system components to reduce dependencies\", metadata={\"Scalability\": \"decoupling\"})\n",
    "document_12 = Document(id=\"12\", page_content=\"Linear regression is a supervised learning algorithm used for predicting continuous values\", metadata={\"Machine Learning\": \"Linear Regression\"})\n",
    "document_13 = Document(id=\"13\", page_content=\"Logistic regression is used for binary classification problems in supervised learning\", metadata={\"Machine Learning\": \"Logistic Regression\"})\n",
    "document_14 = Document(id=\"14\", page_content=\"Decision trees are a type of supervised learning algorithm used for both classification and regression tasks\", metadata={\"Machine Learning\": \"Decision Trees\"})\n",
    "document_15 = Document(id=\"15\", page_content=\"Random forests are an ensemble learning method that constructs multiple decision trees\", metadata={\"Machine Learning\": \"Random Forests\"})\n",
    "document_16 = Document(id=\"16\", page_content=\"Gradient boosting is a machine learning technique for regression and classification problems\", metadata={\"Machine Learning\": \"Gradient Boosting\"})\n",
    "document_17 = Document(id=\"17\", page_content=\"Feature engineering is the process of creating new features from existing data to improve model performance\", metadata={\"Machine Learning\": \"Feature Engineering\"})\n",
    "document_18 = Document(id=\"18\", page_content=\"Feature selection is the process of selecting a subset of relevant features for use in model construction\", metadata={\"Machine Learning\": \"Feature Selection\"})\n",
    "\n",
    "documents = [document_1, document_2, document_3, document_4, document_5]\n",
    "documents.extend([document_6, document_7, document_8, document_9, document_10, document_11])\n",
    "documents.extend([document_12, document_13, document_14, document_15, document_16, document_17, document_18])\n",
    "vector_store.add_documents(documents=documents)\n",
    "# Use the vectorstore as a retriever\n",
    "retriever = vector_store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Feature engineering\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs a similarity search on the vector store and prints the top 3 most similar documents along with their similarity scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await vector_store.asimilarity_search_with_score(query=query, k=3,fetch_k=5)\n",
    "for doc,score in results:\n",
    "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a single text string by combining document contents from search results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ', '.join([doc.page_content for doc, score in results])\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invokes a ChatOllama model with the provided context and query, and returns the model's response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.1\",\n",
    "    temperature = 0.8\n",
    ")\n",
    "\n",
    "messages = [\n",
    "        (\"system\", f\"You answer questions strictly based on this context provided and nothing else. context: {context}. If the answer is not in the context, respond with 'I don't know.'\"),\n",
    "        (\"human\", query),\n",
    "]\n",
    "\n",
    "llm.invoke(messages).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
